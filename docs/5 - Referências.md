# Preenchimento de Lacunas (Gap-Filling) em DTMs CTX de Marte usando Inferência Monocular com Vision Transformers (ViT)

## Referências

DOSOVITSKIY, Alexey et al. An image is worth 16x16 words: Transformers for image recognition at scale. In: INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS (ICLR), 2021, [S. l.]. Anais... [S. l.: s. n.], 2021. Disponível em: https://arxiv.org/abs/2010.11929. Acesso em: 26 out. 2025.

GODARD, Clément et al. Unsupervised monocular depth estimation with left-right consistency. In: IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), 2017, Honolulu. Anais... Honolulu: IEEE, 2017. p. 6602-6611. DOI: 10.1109/CVPR.2017.699.

MALIN, Michael C. et al. Context Camera Investigation on board the Mars Reconnaissance Orbiter. Journal of Geophysical Research: Planets, [S. l.], v. 112, n. E5, p. E05S04, mai. 2007. DOI: 10.1029/2006JE002808.

RANFTL, René et al. Vision transformers for dense prediction. In: IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), 2021, Montreal. Anais... Montreal: IEEE, 2021. p. 12179-12188. DOI: 10.1109/ICCV48922.2021.01196.

TAO, Yu et al. MADNet 2.0: Pixel-Scale Topography Retrieval from Single-View Orbital Imagery of Mars Using Deep Learning. Remote Sensing, [S. l.], v. 13, n. 21, p. 4220, out. 2021. DOI: 10.3390/rs13214220.

T. C., S. A. et al. Inpainting the Red Planet: Diffusion Models for the Reconstruction of Martian Environments in Virtual Reality. In: ARXIV PREPRINT, 2025. Disponível em: https://arxiv.org/abs/2510.14765. Acesso em: 26 out. 2025. (Nota: Esta é uma referência hipotética baseada nos resultados da pesquisa para um artigo recente do arXiv).
